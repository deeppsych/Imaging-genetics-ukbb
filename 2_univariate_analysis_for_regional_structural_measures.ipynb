{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regional structural measures\n",
    "CT_data = pd.read_csv('raw_data/ukbb_CT_DK.csv').dropna(how='any')\n",
    "CSA_data = pd.read_csv('raw_data/ukbb_CSA_DK.csv').dropna(how='any')\n",
    "sub_data = pd.read_csv('raw_data/ukbb_sub_volumes.csv').dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load global structural measures\n",
    "global_data = pd.read_csv('raw_data/global_brain_measures.csv').dropna(how='any')\n",
    "\n",
    "# load scanning positions x,y,z\n",
    "pos_data = pd.read_csv('raw_data/scanning_positions.csv').dropna(how='any')\n",
    "\n",
    "# load covariates \n",
    "age_sex = pd.read_csv('raw_data/ukbb_age_sex.csv').dropna(how='any')\n",
    "cols = ['eid']\n",
    "for i in range(25):\n",
    "    cols.append('PC'+str(i+1))\n",
    "PCs = pd.read_csv('raw_data/top_100_PCs.csv')[cols].dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PRS data\n",
    "PRS_data = pd.read_csv('raw_data/multi_PRSs.csv').dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "CT_data.set_index('eid',inplace=True)\n",
    "CSA_data.set_index('eid',inplace=True)\n",
    "sub_data.set_index('eid',inplace=True)\n",
    "global_data.set_index('eid',inplace=True)\n",
    "pos_data.set_index('eid',inplace=True)\n",
    "age_sex.set_index('eid',inplace=True)\n",
    "PCs.set_index('eid',inplace=True)\n",
    "PRS_data.set_index('eid',inplace=True)\n",
    "\n",
    "l = list(set(CT_data.index) & set(CSA_data.index) & set(sub_data.index) \\\n",
    "         & set(global_data.index) & set(pos_data.index) & set(age_sex.index) & set(PCs.index) & set(PRS_data.index))\n",
    "\n",
    "final_CT = CT_data.loc[l]\n",
    "final_CSA = CSA_data.loc[l]\n",
    "final_sub = sub_data.loc[l]\n",
    "final_global_measures = global_data.loc[l]\n",
    "final_pos = pos_data.loc[l]\n",
    "final_age_sex = age_sex.loc[l]\n",
    "final_PCs = PCs.loc[l]\n",
    "final_PRSs = PRS_data.loc[l]\n",
    "\n",
    "final_CT.reset_index(inplace=True)\n",
    "final_CSA.reset_index(inplace=True)\n",
    "final_sub.reset_index(inplace=True)\n",
    "final_global_measures.reset_index(inplace=True)\n",
    "final_pos.reset_index(inplace=True)\n",
    "final_age_sex.reset_index(inplace=True)\n",
    "final_PCs.reset_index(inplace=True)\n",
    "final_PRSs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create covariates\n",
    "ACT = final_global_measures.iloc[:,3:4].values\n",
    "TCSA = final_global_measures.iloc[:,2:3].values\n",
    "ICV = final_global_measures.iloc[:,1:2].values\n",
    "\n",
    "PCs_25 = final_PCs.iloc[:,1:].values\n",
    "age = final_age_sex.iloc[:,2:3].values\n",
    "sex = final_age_sex.iloc[:,1:2].values\n",
    "postions = final_pos.iloc[:,1:].values\n",
    "sex = sex + 1\n",
    "\n",
    "co_for_CT = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions,ACT))\n",
    "co_for_CSA = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions,TCSA))\n",
    "co_for_sub = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions,ICV))\n",
    "co = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used for regressing out the effects of covariates \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def regression_covariant(covariant_matrix, y, standard_scale=False):\n",
    "    a = np.hstack((covariant_matrix,np.ones((covariant_matrix.shape[0], 1))))\n",
    "    w = np.linalg.lstsq(a,y,rcond=None)[0]\n",
    "\n",
    "    residual = y - covariant_matrix.dot(w[:-1])\n",
    "    residual = residual.astype('float64')\n",
    "\n",
    "    if standard_scale:\n",
    "        residual = StandardScaler().fit_transform(residual.reshape(-1,1)).flatten()\n",
    "\n",
    "    return residual, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_PRSs.iloc[:,1:].values\n",
    "X[:,7] = -X[:,7]\n",
    "X[:,8] = -X[:,8]\n",
    "X[:,11] = -X[:,11]\n",
    "\n",
    "Y_CT = final_CT.iloc[:,1:].values\n",
    "Y_CSA = final_CSA.iloc[:,1:].values\n",
    "Y_sub = final_sub.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def pearsonr_ci(x,y,alpha=0.05):\n",
    "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : iterable object such as a list or np.array\n",
    "      Input for correlation calculation\n",
    "    alpha : float\n",
    "      Significance level. 0.05 by default\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "      Pearson's correlation coefficient\n",
    "    pval : float\n",
    "      The corresponding p value\n",
    "    lo, hi : float\n",
    "      The lower and upper bound of confidence intervals\n",
    "    '''\n",
    "\n",
    "    r, p = stats.pearsonr(x,y)\n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(x.size-3)\n",
    "    z = stats.norm.ppf(1-alpha/2)\n",
    "    lo_z, hi_z = r_z-z*se, r_z+z*se\n",
    "    lo, hi = np.tanh((lo_z, hi_z))\n",
    "    return r, p, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(X,Y,co):\n",
    "    re_R = np.empty((X.shape[1],Y.shape[1]))\n",
    "    re_P = np.empty((X.shape[1],Y.shape[1]))\n",
    "    Low = np.empty((X.shape[1],Y.shape[1]))\n",
    "    High = np.empty((X.shape[1],Y.shape[1]))\n",
    "    for i in range(X.shape[1]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            x = X[:,i]\n",
    "            y = Y[:,j]\n",
    "            [rx,w1] = regression_covariant(co,x,standard_scale=True)\n",
    "            [ry,w1] = regression_covariant(co,y,standard_scale=True)\n",
    "            r,p,lo,hi = pearsonr_ci(rx, ry)\n",
    "            re_R[i,j] = r\n",
    "            re_P[i,j] = p\n",
    "            Low[i,j] = lo\n",
    "            High[i,j] = hi\n",
    "    return re_R,re_P,Low,High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_CT_R, re_CT_P, Low_CT, High_CT= correlation_analysis(X,Y_CT,co_for_CT)\n",
    "re_CSA_R, re_CSA_P, Low_CSA, High_CSA = correlation_analysis(X,Y_CSA,co_for_CSA)\n",
    "re_sub_R, re_sub_P, Low_sub, High_sub = correlation_analysis(X,Y_sub,co_for_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_CIs(Low,High,output_path):\n",
    "    s = Low.shape\n",
    "    for i in range(s[0]):\n",
    "        tmp = []\n",
    "        for j in range(s[1]):\n",
    "            lo = round(Low[i,j], 4)\n",
    "            hi = round(High[i,j], 4)\n",
    "            tmp.append('(' + str(lo) + ' , ' + str(hi) + ')')\n",
    "        if i == 0:\n",
    "            data = pd.DataFrame(data=tmp,columns=[str(i+1)])\n",
    "        else:\n",
    "            data[str(i+1)] = tmp\n",
    "    output_file = output_path + '_CIs.csv'\n",
    "    data.to_csv(output_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_CIs(Low_CT, High_CT,'results/regional_structural_measures/CT')\n",
    "output_CIs(Low_CSA, High_CSA,'results/regional_structural_measures/CSA')\n",
    "output_CIs(Low_sub, High_sub,'results/regional_structural_measures/volume_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge their results (P values) together\n",
    "total_P = np.hstack((re_CT_P,re_CSA_P,re_sub_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest\n",
    "\n",
    "def fdr_correction(P):\n",
    "    size = P.shape\n",
    "    temp_p = P.flatten()\n",
    "    Ps = multitest.multipletests(temp_p,alpha=0.05,method='fdr_bh')\n",
    "    P_corrected = Ps[1].reshape(size)\n",
    "    return P_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_P = fdr_correction(total_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_num = 33\n",
    "re_CT_P_corrected = correct_P[:,:2*region_num]\n",
    "re_CSA_P_corrected = correct_P[:,2*region_num:4*region_num]\n",
    "re_sub_P_corrected = correct_P[:,4*region_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output CSA results\n",
    "lSA_R = re_CSA_R[:,:region_num]\n",
    "lSA_P = re_CSA_P[:,:region_num]\n",
    "lSA_P_corrected = re_CSA_P_corrected[:,:region_num]\n",
    "re_l_R = pd.DataFrame(data=lSA_R)\n",
    "re_l_R.to_csv('results/regional_structural_measures/CSA_left_R.csv',header=None,index=False)\n",
    "re_l_P = pd.DataFrame(data=lSA_P)\n",
    "re_l_P.to_csv('results/regional_structural_measures/CSA_left_P.csv',header=None,index=False)\n",
    "re_l_P_corrected = pd.DataFrame(data=lSA_P_corrected)\n",
    "re_l_P_corrected.to_csv('results/regional_structural_measures/CSA_left_P_corrected.csv',header=None,index=False)\n",
    "\n",
    "rSA_R = re_CSA_R[:,region_num:]\n",
    "rSA_P = re_CSA_P[:,region_num:]\n",
    "rSA_P_corrected = re_CSA_P_corrected[:,region_num:]\n",
    "re_r_R = pd.DataFrame(data=rSA_R)\n",
    "re_r_R.to_csv('results/regional_structural_measures/CSA_right_R.csv',header=None,index=False)\n",
    "re_r_P = pd.DataFrame(data=rSA_P)\n",
    "re_r_P.to_csv('results/regional_structural_measures/CSA_right_P.csv',header=None,index=False)\n",
    "re_r_P_corrected = pd.DataFrame(data=rSA_P_corrected)\n",
    "re_r_P_corrected.to_csv('results/regional_structural_measures/CSA_right_P_corrected.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output CT results\n",
    "lCT_R = re_CT_R[:,:region_num]\n",
    "lCT_P = re_CT_P[:,:region_num]\n",
    "lCT_P_corrected = re_CT_P_corrected[:,:region_num]\n",
    "re_l_R = pd.DataFrame(data=lCT_R)\n",
    "re_l_R.to_csv('results/regional_structural_measures/CT_left_R.csv',header=None,index=False)\n",
    "re_l_P = pd.DataFrame(data=lCT_P)\n",
    "re_l_P.to_csv('results/regional_structural_measures/CT_left_P.csv',header=None,index=False)\n",
    "re_l_P_corrected = pd.DataFrame(data=lCT_P_corrected)\n",
    "re_l_P_corrected.to_csv('results/regional_structural_measures/CT_left_P_corrected.csv',\\\n",
    "                        header=None,index=False)\n",
    "\n",
    "rCT_R = re_CT_R[:,region_num:]\n",
    "rCT_P = re_CT_P[:,region_num:]\n",
    "rCT_P_corrected = re_CT_P_corrected[:,region_num:]\n",
    "re_r_R = pd.DataFrame(data=rCT_R)\n",
    "re_r_R.to_csv('results/regional_structural_measures/CT_right_R.csv',header=None,index=False)\n",
    "re_r_P = pd.DataFrame(data=rCT_P)\n",
    "re_r_P.to_csv('results/regional_structural_measures/CT_right_P.csv',header=None,index=False)\n",
    "re_r_P_corrected = pd.DataFrame(data=rCT_P_corrected)\n",
    "re_r_P_corrected.to_csv('results/regional_structural_measures/CT_right_P_corrected.csv',\\\n",
    "                        header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output results of subcortical volumes \n",
    "subvol_R = re_sub_R\n",
    "subvol_P = re_sub_P\n",
    "subvol_P_corrected = re_sub_P_corrected\n",
    "re_sub_R = pd.DataFrame(data=subvol_R)\n",
    "re_sub_R.to_csv('results/regional_structural_measures/volume_sub_R.csv',header=None,index=False)\n",
    "re_sub_P = pd.DataFrame(data=subvol_P)\n",
    "re_sub_P.to_csv('results/regional_structural_measures/volume_sub_P.csv',header=None,index=False)\n",
    "re_sub_P_corrected = pd.DataFrame(data=subvol_P_corrected)\n",
    "re_sub_P_corrected.to_csv('results/regional_structural_measures/volume_sub_P_corrected.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
